{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data / Drop Data / Dependent Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/dufesweeney_gmail_com/input/database_stal.csv', na_values='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna (axis=1, how='all', inplace=True)\n",
    "dataset.replace ('None', 0, regex=True, inplace=True)\n",
    "\n",
    "dataset.drop (columns=['Unnamed: 0', 'assettypenumber', 'primaryloanservicername'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_asset = dataset[dataset.assetnumber.isin(dataset[dataset.loc[:, 'zerobalancecode']==4].assetnumber)].assetnumber\n",
    "dataset['Ever Defaulted']= dataset['assetnumber'].isin(default_asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.691419\n",
       "True     0.308581\n",
       "Name: Ever Defaulted, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Ever Defaulted'].value_counts()/len(dataset['Ever Defaulted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.754969\n",
       "1    0.245031\n",
       "Name: delinquency, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many people deliquent in this pool\n",
    "dataset['delinquency']=dataset['currentdelinquencystatus'].apply(lambda x: 0 if x < 32 else 1)\n",
    "dataset['delinquency'].value_counts()/len(dataset['delinquency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2762289796120839"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given the unique individuals, how many of those defaulted ? \n",
    "len(dataset[dataset.loc[:, 'zerobalancecode']==4]['assetnumber'].value_counts())/len(dataset.assetnumber.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "west = [\"WA\", \"OR\", \"CA\", \"ID\", \"NV\", \"UT\", \"MT\", \"WY\", \"CO\"]\n",
    "mid_west = [\"ND\", \"SD\", \"NE\", \"KS\", \"MN\", \"IA\", \"MO\", \"WI\", \"IL\", \"MI\", \"IN\", \"OH\"]\n",
    "northeast = [\"NY\", \"VT\", \"ME\", \"PA\", \"NH\", \"MA\", \"RI\", \"CT\", \"NJ\", \"DE\", \"MD\", \"DC\"]\n",
    "non_deep_south = [\"AR\", \"TN\", \"KY\", \"WV\", \"VA\", \"FL\", \"MD\", \"AZ\", \"NM\", \"TX\", \"OK\"]\n",
    "deep_south = [\"AL\", \"GA\", \"LA\", \"MS\", \"SC\", \"NC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"West\"] = dataset['obligorgeographiclocation'].isin(west)\n",
    "dataset[\"Mid West\"] = dataset['obligorgeographiclocation'].isin(mid_west)\n",
    "dataset[\"Northeast\"] = dataset['obligorgeographiclocation'].isin(northeast)\n",
    "dataset[\"South\"] = dataset['obligorgeographiclocation'].isin(non_deep_south)\n",
    "dataset[\"Deep South\"] = dataset['obligorgeographiclocation'].isin(deep_south)\n",
    "# dataset[\"Deep South\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['vehiclenewusedcode'] = dataset['vehiclenewusedcode'].replace({1:True, 2:False}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.707203\n",
       "1    0.292797\n",
       "Name: delinquency, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= dataset.drop_duplicates(subset=\"assetnumber\")\n",
    "dataset['delinquency'].value_counts()/len(dataset['delinquency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_factors = ['subvented', 'vehicletypecode', 'vehiclevaluesourcecode',\n",
    "               'obligoremploymentverificationcode','obligorincomeverificationlevelcode'] \n",
    "\n",
    "var_quants = ['originalloanamount', 'originalloanterm', 'originalinterestratepercentage',\n",
    "              'obligorcreditscore','paymenttoincomepercentage', 'remainingtermtomaturitynumber', \n",
    "              'servicingfeepercentage', 'totalactualamountpaid']\n",
    "\n",
    "var_geo = ['West', 'Mid West', 'Northeast', 'South', 'Deep South']\n",
    "var = var_factors + var_quants + var_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.drop(dataset[~dataset['zerobalancecode'].isna()].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop zero balance code \n",
    "dataset.drop(['zerobalancecode'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat dependent variables\n",
    "var_drop = list(set(dataset.columns.values)-set(var))\n",
    "dataset = pd.get_dummies(dataset, columns=var_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=var_drop)\n",
    "y = dataset[['Ever Defaulted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17214176380548687"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['Ever Defaulted'].sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67944, 28), (67944, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_na = X.loc[:, X.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_na = y.loc[:, y.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_na.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['originalloanterm', 'originalinterestratepercentage', 'obligorcreditscore', 'paymenttoincomepercentage', 'remainingtermtomaturitynumber', 'totalactualamountpaid'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_na.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_impute = imp_mean.fit_transform(X_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_impute = pd.DataFrame(X_impute, columns=list(X_na.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=X_na.columns.to_list(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(X_na.columns):\n",
    "    X[col] = X_impute.loc[:, col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67944, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1197882465.89"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['originalloanamount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Step 1: TestTrain Split - Stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install xgboost\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shapes:\n",
      " X_train: X_validation:\n",
      " (54355, 28) \n",
      "\n",
      "Y_shapes:\n",
      " Y_train: Y_validation:\n",
      " (54355, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_shapes:\\n', 'X_train:', 'X_validation:\\n', X_train.shape ,'\\n')\n",
    "print('Y_shapes:\\n', 'Y_train:', 'Y_validation:\\n', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ML Step 2: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Spot-Checking Algorithms\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('LR', LogisticRegression(n_jobs=8)))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('XGB', XGBClassifier(n_jobs=8)))\n",
    "models.append(('RF', RandomForestClassifier(n_jobs=8)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=5,metric='euclidean')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.662003 (0.007161)\n",
      "CART: 0.569287 (0.005001)\n",
      "XGB: 0.746501 (0.004853)\n"
     ]
    }
   ],
   "source": [
    "#testing models\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=5)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = '%s: %f (%f)' % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compare Algorithms\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "plt.title('Comparison of Classification Algorithms')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('ROC-AUC Score')\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nb.predict(X_test)\n",
    "# print(pd.crosstab(y_test, preds, rownames=['Actual '], colnames=['Predicted ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_jobs=8)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape([len(y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = xgb.predict(X_test)\n",
    "print(pd.crosstab(y_test, preds, rownames=['Actual '], colnames=['Predicted ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# import pickle\n",
    "# # # Save to file in the current working directory\n",
    "# joblib_file = \"XGBoost_gm.pkl\"\n",
    "# joblib.dump(xgb, joblib_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_roc_auc = roc_auc_score(y_test, xgb.predict(X_test))\n",
    "random_fpr, random_tpr, random_thresholds = roc_curve(y_test, xgb.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(random_fpr, random_tpr, label='XGBoost (area = %0.2f)' % random_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_xgb = pd.DataFrame(list(zip(X, xgb.feature_importances_)), columns=['Features', 'Importances'])\n",
    "importance_df_xgb = importance_df_xgb.sort_values(by=['Importances'], ascending=False)\n",
    "plot_importance = importance_df_xgb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_xgb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "plt.bar(x=plot_importance['Features'], height=plot_importance['Importances'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = DecisionTreeClassifier()\n",
    "cart.fit(X_train, y_train)\n",
    "preds = cart.predict(X_test)\n",
    "print(pd.crosstab(y_test, preds, rownames=['Actual '], colnames=['Predicted ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Save to file in the current working directory\n",
    "# joblib_file = \"CART_gm.pkl\"\n",
    "# joblib.dump(cart, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_roc_auc = roc_auc_score(y_test, cart.predict(X_test))\n",
    "random_fpr, random_tpr, random_thresholds = roc_curve(y_test, cart.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(random_fpr, random_tpr, label='Decision Tree (area = %0.2f)' % random_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_cart = pd.DataFrame(list(zip(X, cart.feature_importances_)), columns=['Features', 'Importances'])\n",
    "importance_df_cart = importance_df_cart.sort_values(by=['Importances'], ascending=False)\n",
    "plot_importance = importance_df_cart.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_cart.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "plt.bar(x=plot_importance['Features'], \n",
    "        height=plot_importance['Importances'], \n",
    "        color=['black', 'red', 'blue', 'cyan', 'green'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance['Importances'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_jobs=8)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "preds = RF.predict(X_test)\n",
    "print(pd.crosstab(y_test, preds, rownames=['Actual '], colnames=['Predicted ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Save to file in the current working directory\n",
    "# joblib_file = \"RandomForest_gm.pkl\"\n",
    "# joblib.dump(RF, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_roc_auc = roc_auc_score(y_test, RF.predict(X_test))\n",
    "random_fpr, random_tpr, random_thresholds = roc_curve(y_test, RF.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(random_fpr, random_tpr, label='Random Forest (area = %0.2f)' % random_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_rf = pd.DataFrame(list(zip(X, RF.feature_importances_)), columns=['Features', 'Importances'])\n",
    "importance_df_rf = importance_df_rf.sort_values(by=['Importances'], ascending=False)\n",
    "plot_importance = importance_df_rf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_rf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "plt.bar(x=plot_importance['Features'], height=plot_importance['Importances'])\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
